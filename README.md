# Handwritten-Digits-Classifier-with-PyTorch

This project is designed to help you build your own custom neural network architecture to classify handwritten digits from the MNIST database of handwritten digits. The MNIST dataset is a popular benchmark for image recognition tasks and achieving high accuracy on this dataset is a good indication that your model is functioning well.

#### **Introduction**

In this project, you will  construct a neural network  using Python libraries to classify images of handwritten digits from 0 to 9 in the MNIST dataset. You will train the model on a portion of the data and evaluate its performance on a separate testing set. 

#### **MNIST Dataset**

The MNIST database of handwritten digits consists of 70,000 images, each labeled with the corresponding digit it represents. The images are 28x28 pixels in grayscale format.

![image](https://github.com/user-attachments/assets/734f0c39-6b8a-4b41-b110-89f51e9748ac)


#### **Requirements**

This project requires the following Python libraries to be installed:

* numpy
* matplotlib
* pillow
* torch
* torchvision
* tqdm
* ipywidgets
* livelossplot

You can install these libraries using the following command in your terminal:

```
pip install numpy matplotlib pillow torch torchvision tqdm ipywidgets livelossplot
```

#### **Installation**

1. Clone this repository or download the project files.
2. Open a terminal or command prompt and navigate to the project directory.
3. Run the following command to install the required libraries:

```
pip install -r requirements.txt
```

#### **Usage**

1. Open a Jupyter Notebook or your preferred Python development environment.
2. Open the provided Jupyter Notebook file (e.g., `mnist_nn.ipynb`).
3. The notebook will guide you through the process of loading the data, building the neural network architecture, training the model, and evaluating its performance.

#### **Further Exploration**

* Experiment with different neural network architectures (number of layers, neurons per layer, activation functions).
* Try different optimization algorithms (e.g., Adam instead of SGD).
* Visualize the training process using libraries like `livelossplot`.
* Explore techniques for data augmentation to improve the model's generalization ability.

#### **Resources**

* MNIST dataset: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
* Deep Learning with PyTorch: [https://www.manning.com/books/deep-learning-with-pytorch](https://www.manning.com/books/deep-learning-with-pytorch)
* Neural Networks and Deep Learning: [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)


I hope this README provides a clear and concise overview of the project!
